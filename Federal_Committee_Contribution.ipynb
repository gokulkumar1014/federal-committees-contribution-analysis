{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "066aaa91-4883-4b2e-887e-17d8297d84dc",
   "metadata": {},
   "source": [
    "## DATA MANAGEMENT FOR ANALYTICS - DNSC 6305"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0f6360a-35eb-418b-8555-d3b20ed7030d",
   "metadata": {},
   "source": [
    "## INDIVIDUAL ASSIGNMENT"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "095dc4c3-7832-43ed-a2d4-8a003d1c3380",
   "metadata": {},
   "source": [
    "#### GOKUL KUMAR KESAVAN - G25385029"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad3df07c-1a4c-4087-bfe9-7fe4ac35f291",
   "metadata": {},
   "source": [
    "In this task, we conducted a detailed analysis of individual contributions to Federal Committees such as Presidential, Senate and House committees for the period between June 20, 2024, and July 23, 2024. Using Apache Spark's distributed computing capabilities, we processed and analyzed large datasets to extract meaningful insights about the patterns and trends of political contributions during this time frame."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ada4b06e-775f-42c4-94b9-ce240db1d54b",
   "metadata": {},
   "source": [
    "## DATA COLLECTION"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd23f1c0-52f7-445d-9628-1d4c3fd5c323",
   "metadata": {},
   "source": [
    "The data for this analysis was obtained from the [Federal Election Commission (FEC)](https://www.fec.gov/data/browse-data/?tab=bulk-data) and consists of individual contributions to political committees.\n",
    "\n",
    "We have used the 2023-2024 contributions dataset. The files of interest for this task include:\n",
    "- itcont_2024_20240620_20240709.txt: Covers the period from June 20,2024, to July 09,2024.  \n",
    "- itcont_2024_20240710_20240723.txt: Covers the period from July 10,2024, to July 23,2024.\n",
    "                                                                       \n",
    "These files are delimited using the pipe symbol ( | ) and contain all contributions reported by individuals within the specified duration."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ad47060-ff68-4da0-b525-521995bde6c4",
   "metadata": {},
   "source": [
    "The [Individual Data Dictionary](https://www.fec.gov/campaign-finance-data/contributions-individuals-file-description/) provides detailed information about the fields present in the data files. Some of the key attributes include:\n",
    "\n",
    "- CMTE_ID: Committee ID receiving the contribution. \n",
    "- NAME: Name of the contributor. \n",
    "- TRANSACTION_AMT: Contribution amount. \n",
    "- CITY, STATE, ZIP_CODE: Geographical details. \n",
    "- EMPLOYER and OCCUPATION: Employment details of the contributor.\n",
    "\n",
    "To understand the structure of the data, the file header provided with the dataset is used. It defines the columns and their respective order, ensuring proper data mapping and processing."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ced674dc-54f2-46b9-98e5-b69db876fc7d",
   "metadata": {},
   "source": [
    "## DATA PROCESSING"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e32a0a7-53b2-49d5-ba8d-20720202092e",
   "metadata": {},
   "source": [
    "We used an AWS EC2 t2.large instance with 60+ GB of data storage to process and analyze the data. This instance provides sufficient computational power and storage for handling large datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9f50220a-8f93-4c15-9fd9-c83174ab1f57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ubuntu\n"
     ]
    }
   ],
   "source": [
    "#To make sure we are in the right directory\n",
    "!pwd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb017d0b-12e2-4bf6-a112-a689a574f194",
   "metadata": {},
   "source": [
    "We began by uploading the zip file containing the two raw text documents (itcont_2024_20240620_20240709.txt and itcont_2024_20240710_20240723.txt) along with the header file indiv_header_file.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ea5279fb-c970-428f-971b-3984c94f1845",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archive:  Ind_Assign_AWS.zip\n",
      "  inflating: ./Ind_Assign_AWS/itcont_2024_20240620_20240709.txt  \n",
      "  inflating: ./Ind_Assign_AWS/itcont_2024_20240710_20240723.txt  \n"
     ]
    }
   ],
   "source": [
    "# Unzipping the file and storing them into a new folder using !unzip command\n",
    "# -o : Overwrites existing files in the target directory\n",
    "# -d : Specifies the destination directory where the contents will be extracted\n",
    "!unzip -o Ind_Assign_AWS.zip -d ./Ind_Assign_AWS/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "81b8811b-8372-4fa9-be01-fa1cf58e95a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Deleing the zip folder\n",
    "!rm Ind_Assign_AWS.zip"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "251389ce-0506-45f9-9365-40e583cf0b62",
   "metadata": {},
   "source": [
    "The original data files were in ( | ) delimited format. To facilitate further processing, we convert these files into CSV format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5063df2d-b900-4e70-b3b4-171dd04f0888",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !csvformat : A command from the csvkit library used to format and manipulate CSV files\n",
    "# -d \"|\": Specifies the delimiter used in the input file\n",
    "# Ind_Assign_AWS/itcont_2024_20240620_20240709.txt : Path of the input file\n",
    "# > : This symbol redirects the output of the csvformat command to a new file\n",
    "# June2024.csv, July2024: Name of the ouput file\n",
    "!csvformat -d \"|\" Ind_Assign_AWS/itcont_2024_20240620_20240709.txt > June2024.csv\n",
    "!csvformat -d \"|\" Ind_Assign_AWS/itcont_2024_20240710_20240723.txt > July2024.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a7e614d2-12ac-46fc-aca8-e54b5a98269f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No errors.\n",
      "No errors.\n"
     ]
    }
   ],
   "source": [
    "# !csvclean : A command from the csvkit library used to clean and validate CSV files\n",
    "# -n : The \"dry-run\" option, which validates the file without actually modifying it\n",
    "!csvclean -n June2024.csv\n",
    "!csvclean -n July2024.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a00b77b-170e-4b97-88cc-3ac1fb41eecc",
   "metadata": {},
   "source": [
    "After validating the files, we concatenated the header file (indiv_header_file.csv) with the two CSV files (June2024.csv and July2024.csv) to create a single unified file named final.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "899797d5-59f1-46d8-a784-ed90c02092d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "!cat indiv_header_file.csv > final.csv\n",
    "\n",
    "!cat June2024.csv >> final.csv\n",
    "!cat July2024.csv >> final.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc4e1f87-5143-4083-a445-2e0ddd5f66a2",
   "metadata": {},
   "source": [
    "To verify the integrity of the combined dataset, we use the wc -l command to count the number of rows in the individual files and the final combined file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a73d0503-af64-4e6f-b508-b195f97b49c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 indiv_header_file.csv\n",
      "1944602 Ind_Assign_AWS/itcont_2024_20240620_20240709.txt\n",
      "1902192 Ind_Assign_AWS/itcont_2024_20240710_20240723.txt\n",
      "3846795 final.csv\n"
     ]
    }
   ],
   "source": [
    "# wc : Word count, can also be used to count line, words or character in a file\n",
    "# -l : It tells the wc to count the total number of lines in a given file \n",
    "!wc -l indiv_header_file.csv\n",
    "!wc -l Ind_Assign_AWS/itcont_2024_20240620_20240709.txt\n",
    "!wc -l Ind_Assign_AWS/itcont_2024_20240710_20240723.txt\n",
    "!wc -l final.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18d7f9a1-a163-45e3-9371-dd79b0f41bb2",
   "metadata": {},
   "source": [
    "The total number of rows in Final.csv is the sum of all three files. This confirms that all rows from the individual files were successfully concatenated into the final.csv file"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29965ca4-e4d4-4a4c-b768-ed9fbd5df328",
   "metadata": {},
   "source": [
    "Removing intermediate files and directories to free up storage space and keep the workspace organized, as they are no longer needed after generating the final dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "39c50016-be5d-4933-9df0-8147d5100483",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Deleting the unzipped folder\n",
    "# !rm -r: Command to remove files or directories\n",
    "!rm -r Ind_Assign_AWS\n",
    "\n",
    "# Deleteing the header file and intermediate file generated after converting data from | to CSV format\n",
    "!rm June2024.csv\n",
    "!rm July2024.csv\n",
    "!rm indiv_header_file.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05edeeb7-7d4d-4a59-bee3-b3822036b561",
   "metadata": {},
   "source": [
    "## DATA ANALYSIS PART 1: RDD PROCESSING"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73dcad6a-966c-4b6e-8015-1ef91c71603d",
   "metadata": {},
   "source": [
    "Every time we use Spark, we'll have to run the following steps:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "88c81932-6c2a-4cf0-b010-77825ca9c45b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e84af156-00c9-4aa4-ac2e-05a73645de05",
   "metadata": {},
   "outputs": [],
   "source": [
    "findspark.init()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89e747cc-3f8a-4d7f-831e-e99cb526ceaf",
   "metadata": {},
   "source": [
    "The next two steps are required for the simple Python style of using Spark :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7b06bb1c-fac4-448e-9d4c-c36d533f2994",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark import SparkContext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7311f2e6-9015-47a0-b214-2714bf370a56",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "24/11/24 16:53:02 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "spark = SparkContext(appName= 'AWS_Assignment3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "363d456a-9757-485e-ad82-a8e04ced60cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://ip-172-31-18-66.ec2.internal:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.5.2</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>AWS_Assignment3</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        "
      ],
      "text/plain": [
       "<SparkContext master=local[*] appName=AWS_Assignment3>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bf2ef8b3-a872-4ae7-bff0-2793b475bd71",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Topstates: This is the variable that stores the RDD created from the final.csv file\n",
    "# spark.textFile(): Method provided by Apache Spark's RDD (Resilient Distributed Dataset) API to read a text file\n",
    "Topstates = spark.textFile('final.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bf70941c-891f-4a70-9966-4c6828e465a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'CMTE_ID,AMNDT_IND,RPT_TP,TRANSACTION_PGI,IMAGE_NUM,TRANSACTION_TP,ENTITY_TP,NAME,CITY,STATE,ZIP_CODE,EMPLOYER,OCCUPATION,TRANSACTION_DT,TRANSACTION_AMT,OTHER_ID,TRAN_ID,FILE_NUM,MEMO_CD,MEMO_TEXT,SUB_ID'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/11/24 16:53:17 WARN GarbageCollectionMetrics: To enable non-built-in garbage collector(s) List(G1 Concurrent GC), users should configure it(them) to spark.eventLog.gcMetrics.youngGenerationGarbageCollectors or spark.eventLog.gcMetrics.oldGenerationGarbageCollectors\n"
     ]
    }
   ],
   "source": [
    "# Retrieve the header row of the dataset containing column names.\n",
    "header = Topstates.first()\n",
    "header"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cceef92-0719-4ff3-a9fa-ff1430bbdadb",
   "metadata": {},
   "source": [
    "#### Using code and the function 'add', we are going to find:\n",
    "1. Top 10 States by Contribution Count:\n",
    "    - Identifying the top 10 states based on the total 'count' of contributions.\n",
    "2. Top 10 States by Contribution Amount:\n",
    "   - Identifying the top 10 states based on the 'sum' of contribution amounts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b9d37af4-62d9-41bc-95c5-c2a6d29f2a22",
   "metadata": {},
   "outputs": [],
   "source": [
    "from operator import add"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e60ecba1-12cf-4c30-ae11-9d681d9b85d0",
   "metadata": {},
   "source": [
    "### 1. Top 10 States by Contribution Count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "aa451e9e-9a96-4c75-a660-b52588c04a00",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 2:============================================>            (17 + 2) / 22]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CA\t564941\n",
      "TX\t324187\n",
      "FL\t279517\n",
      "NY\t225839\n",
      "WA\t140701\n",
      "PA\t130224\n",
      "VA\t125452\n",
      "IL\t124756\n",
      "AZ\t114972\n",
      "OH\t109487\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "top10 = Topstates.filter(lambda row: row != header) \\\n",
    "    .map(lambda row: row.replace('\"', '')) \\\n",
    "    .map(lambda row: row.split(\",\")) \\\n",
    "    .map(lambda cols: (cols[10], 1)) \\\n",
    "    .reduceByKey(add) \\\n",
    "    .takeOrdered(10, key=lambda pair: -pair[1])\n",
    "for STATE, count in top10:\n",
    "    print(\"{}\\t{}\".format(STATE, count))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abba2644-73ef-4622-a8e1-c08968fb0aa9",
   "metadata": {},
   "source": [
    "#### EXPLANATION OF THE ABOVE CODE:\n",
    "##### 1. filter(lambda row: row != header):\n",
    "- Removes the header row from the dataset (Topstates).\n",
    "##### 2. map(lambda row: row.replace('\"', '')):\n",
    "- Removes double quotes (\") from each row to clean the data.\n",
    "- This step ensures no issues arise due to extra quotes during processing.             \n",
    "##### 3. map(lambda row: row.split(\",\")):\n",
    "- Splits each row into a list of columns using a comma delimiter (\",\").\n",
    "##### 4. map(lambda cols: (cols[10], 1)):\n",
    "- Extracts the state information from column index 10 (The column representing the state).\n",
    "- Maps each state to the value 1, marking each contribution as a single count.       \n",
    "##### 5. reduceByKey(add):\n",
    "- Groups all the contributions by the state (key) and sums up the counts (value) for each state.\n",
    "##### 6. takeOrdered(10, key=lambda pair: -pair[1]):\n",
    "- Extracts the top 10 states based on the count of contributions in descending order.\n",
    "- key=lambda pair: -pair[1] ensures sorting is done in descending order of the second element (the count).\n",
    "##### 7. for STATE, count in top10::\n",
    "- Iterates over the top 10 states and their respective contribution counts.\n",
    "##### 8. print(\"{}\\t{}\".format(STATE, count)):\n",
    "- Prints each state and its contribution count in a tab-separated format."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b9ec649-ab7e-419d-84b3-c6e88f1d73e0",
   "metadata": {},
   "source": [
    "### 2. Top 10 States by Contribution Amount"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d080bb93-f392-4333-9bd7-10fca5f63763",
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_valid_float(value):\n",
    "    try:\n",
    "        float(value)\n",
    "        return True\n",
    "    except (ValueError, TypeError):\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9a9d6591-428f-483f-b91b-a4caea30766e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 4:=========================================>               (16 + 2) / 22]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CA\t64846446564.0\n",
      "TX\t55446914035.0\n",
      "IL\t34138029513.0\n",
      "NY\t30557933743.0\n",
      "FL\t26208594146.0\n",
      "GA\t23379784573.0\n",
      "VA\t21874918857.0\n",
      "PA\t21375698873.0\n",
      "NJ\t20531460523.0\n",
      "MA\t18481600069.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "top10_tot_amount = Topstates.filter(lambda row: row != header) \\\n",
    "    .map(lambda row: row.replace('\"', '')) \\\n",
    "    .map(lambda row: row.split(\",\")) \\\n",
    "    .filter(lambda cols: cols[15] is not None) \\\n",
    "    .filter(lambda cols: is_valid_float(cols[15])) \\\n",
    "    .map(lambda cols: (cols[10], float(cols[15]))) \\\n",
    "    .reduceByKey(add) \\\n",
    "    .takeOrdered(10, key=lambda pair: -pair[1])\n",
    "for STATE, total in top10_tot_amount:\n",
    "    print(\"{}\\t{}\".format(STATE, total))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff1284d8-ad82-4c0e-adaa-ccb71f70abe7",
   "metadata": {},
   "source": [
    "#### EXPLANATION OF THE ABOVE CODE:\n",
    "##### 1. filter(lambda row: row != header):\n",
    "- Removes the header row from the dataset (Topstates).\n",
    "##### 2. map(lambda row: row.replace('\"', '')):\n",
    "- Removes double quotes (\") from each row to clean the data.\n",
    "- This step ensures no issues arise due to extra quotes during processing.             \n",
    "##### 3. map(lambda row: row.split(\",\")):\n",
    "- Splits each row into a list of columns using a comma delimiter (\",\").\n",
    "##### 4. filter(lambda cols: cols[15] is not None):\n",
    "- Ensures that the value in column 15 (transaction amount) is not None\n",
    "##### 5. filter(lambda cols: is_valid_float(cols[15])):\n",
    "- Uses the helper function is_valid_float to check whether the value in column 15 is a valid floating-point number.\n",
    "- Ensures that only numeric transaction amounts are processed.\n",
    "##### 6. map(lambda cols: (cols[10], float(cols[15]))):\n",
    "- Extracts the state information from column 10 and the transaction amount from column 15.\n",
    "- Converts the transaction amount into a floating-point number.       \n",
    "##### 5. reduceByKey(add):\n",
    "- Groups all the contributions by the state (key) and sums up the total transaction amount (value) for each state.\n",
    "##### 6. takeOrdered(10, key=lambda pair: -pair[1]):\n",
    "- Extracts the top 10 states based on the total transaction amount in descending order.\n",
    "- The negative sign (-pair[1]) ensures descending order by the second element (the total amount).\n",
    "##### 7. for STATE, count in top10::\n",
    "- Iterates over the top 10 states and their respective total contribution counts.\n",
    "##### 8. print(\"{}\\t{}\".format(STATE, count)):\n",
    "- Prints each state and its total contribution in a tab-separated format."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e356225-974d-4d71-9949-87ab76542912",
   "metadata": {},
   "source": [
    "## Summary and Insights: RDD Processing Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "271d3684-99d4-4649-a11b-18a0165bd13e",
   "metadata": {},
   "source": [
    "### Findings:\n",
    "1. Top 10 States by Contribution Count:\n",
    "- California (CA) leads the list with the highest number of contributions, followed by Texas (TX), Florida (FL), and New York (NY).\n",
    "- States like Illinois (IL) and Pennsylvania (PA) also show significant contributions, which reflects their importance as swing states in political campaigns.\n",
    "\n",
    "2. Top 10 States by Contribution Amount:\n",
    "- California (CA) again dominates in total contribution amounts, with Texas (TX) close behind, contributing billions during the observed period.\n",
    "- Illinois (IL), Florida (FL), and Georgia (GA) also indicating strong financial support from contributors in these states.\n",
    "- The presence of Virginia (VA) and Pennsylvania (PA) in the top list suggests that they are strategic hubs for fundraising, possibly due to their proximity to Washington, D.C., and their influence in national politics.\n",
    "    \n",
    "### Patterns and Trends Observed:\n",
    "1. Contribution Volume vs Amount:\n",
    "- States like California and Texas consistently rank high in both contribution count and monetary contributions, indicating high political engagement and wealth distribution.\n",
    "2. Regional Influence:\n",
    "- Most contributions come from states with larger economies or political importance, highlighting the political engagement, and campaign funding.\n",
    "\n",
    "### Reflection on Findings:\n",
    "- The dominance of California and Texas is expected due to their large populations, economic strength and their strategic roles in presidential and congressional elections.\n",
    "- The significant contributions from Virginia align with their political significance as battleground states for campaign activities.\n",
    "\n",
    "### Significance in Political Campaigns and Elections:\n",
    "1. Impact on Campaign Strategies:\n",
    "- States like California and Texas act as key fundraising locations, shaping where candidates focus their campaign efforts.\n",
    "- The patterns suggest the need for targeted campaigning in high-contribution states to maximize financial support."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05faf70e-54b0-4aa9-953c-1eee1124910b",
   "metadata": {},
   "source": [
    "### DATA ANALYSIS PART 2: DATA FRAME API"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35c26b13-32ff-46ff-b1ac-e29fae117454",
   "metadata": {},
   "source": [
    "First we obtain a `SQLContext` frm our existing `SparkContext`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "19c14c23-dc38-417c-8e6b-c5a80921b507",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark import SQLContext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "76a57699-75c4-41a8-9ac5-8901d62e3759",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/spark/python/pyspark/sql/context.py:113: FutureWarning: Deprecated in 3.0.0. Use SparkSession.builder.getOrCreate() instead.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "sqlc = SQLContext(spark)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ec05c124-086d-48cd-adbd-bd37af006992",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<pyspark.sql.context.SQLContext at 0x736523522840>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sqlc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5a78031a-99b6-422c-9b5d-0ead7f0c7775",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# sqlc.read.csv: This method is  used to read a CSV file and create a Spark DataFrame\n",
    "dataframe_api = sqlc.read.csv(\"final.csv\", header=True, inferSchema=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "3bbb243d-85a4-474e-897d-ec4d38fbed6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- CMTE_ID: string (nullable = true)\n",
      " |-- AMNDT_IND: string (nullable = true)\n",
      " |-- RPT_TP: string (nullable = true)\n",
      " |-- TRANSACTION_PGI: string (nullable = true)\n",
      " |-- IMAGE_NUM: long (nullable = true)\n",
      " |-- TRANSACTION_TP: string (nullable = true)\n",
      " |-- ENTITY_TP: string (nullable = true)\n",
      " |-- NAME: string (nullable = true)\n",
      " |-- CITY: string (nullable = true)\n",
      " |-- STATE: string (nullable = true)\n",
      " |-- ZIP_CODE: string (nullable = true)\n",
      " |-- EMPLOYER: string (nullable = true)\n",
      " |-- OCCUPATION: string (nullable = true)\n",
      " |-- TRANSACTION_DT: integer (nullable = true)\n",
      " |-- TRANSACTION_AMT: integer (nullable = true)\n",
      " |-- OTHER_ID: string (nullable = true)\n",
      " |-- TRAN_ID: string (nullable = true)\n",
      " |-- FILE_NUM: integer (nullable = true)\n",
      " |-- MEMO_CD: string (nullable = true)\n",
      " |-- MEMO_TEXT: string (nullable = true)\n",
      " |-- SUB_ID: long (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# The method printSchema() is used to display the schema of a Spark DataFrame in a human-readable format.\n",
    "dataframe_api.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "995d0aa9-d950-47b6-9327-2d6cc962772d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 7:=================================================>         (5 + 1) / 6]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+---------+\n",
      "|summary|  CMTE_ID|\n",
      "+-------+---------+\n",
      "|  count|  3846794|\n",
      "|   mean|     NULL|\n",
      "| stddev|     NULL|\n",
      "|    min|C00000059|\n",
      "|    max|C99002396|\n",
      "+-------+---------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# describe() : Generates basic statistics for the specified columns and can be used for any column\n",
    "dataframe_api.describe('CMTE_ID').show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf0c359f-9f97-4d6c-bc29-c3b27bd2fde1",
   "metadata": {},
   "source": [
    "### 1. The Top 10 contributor’s name, the committee ID the contributor contributed to and the transaction amount for all contributions above $5000 ordering them by the transaction amount in descending order"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "8e0506cf-745b-4d8c-bb07-a62dc97e6338",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 10:================================================>         (5 + 1) / 6]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+---------+---------------+\n",
      "|                NAME|  CMTE_ID|TRANSACTION_AMT|\n",
      "+--------------------+---------+---------------+\n",
      "|     MELLON, TIMOTHY|C00825851|       50000000|\n",
      "|          ONE NATION|C00571703|       18400000|\n",
      "|SECURING AMERICAN...|C00881805|       15000000|\n",
      "|FUTURE FORWARD US...|C00669259|       15000000|\n",
      "|CLEMENT, CHRISTIN...|C00857128|       12000000|\n",
      "|BLOOMBERG, MICHAE...|C00495028|       10000000|\n",
      "|     SINGER, PAUL E.|C00504530|       10000000|\n",
      "|SINGER, PAUL ELLIOTT|C00571703|       10000000|\n",
      "|BRICK BY BRICK FO...|C00631549|        5000000|\n",
      "|AMERICAN ACTION N...|C00504530|        5000000|\n",
      "+--------------------+---------+---------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "dataframe_api.filter(\"TRANSACTION_AMT > 5000\") \\\n",
    "    .select(\"NAME\",\"CMTE_ID\",\"TRANSACTION_AMT\") \\\n",
    "    .orderBy(\"TRANSACTION_AMT\", ascending=False) \\\n",
    "    .show(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cad0e17-302e-4e24-99e1-8e896e7a4ad5",
   "metadata": {},
   "source": [
    "#### EXPLANATION OF THE ABOVE CODE:\n",
    "##### 1. dataframe_api.filter(\"TRANSACTION_AMT > 5000\"):\n",
    "- Filters rows in the DataFrame dataframe_api where the TRANSACTION_AMT column is greater than 5000.\n",
    "##### 2. select(\"NAME\", \"CMTE_ID\", \"TRANSACTION_AMT\"):\n",
    "- Selects only the specified columns (NAME, CMTE_ID, and TRANSACTION_AMT) from the filtered DataFrame.\n",
    "- The resulting DataFrame contains only these three columns.\n",
    "##### 3. orderBy(\"TRANSACTION_AMT\", ascending=False):\n",
    "- Sorts the filtered and selected DataFrame in descending order (ascending=False) based on the TRANSACTION_AMT column.\n",
    "##### 4. show(10):\n",
    "- Displays the top 10 rows of the sorted DataFrame in the output."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fd39e38-f290-478e-84e3-f1647cd5f872",
   "metadata": {},
   "source": [
    "### 2. The Top 10 name of the individual and their total contributions ordering them by the total transaction amount in descending order"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "3f73b401-d6e0-4804-9583-74721cc876ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "#imports the sum function from the pyspark.sql.functions module\n",
    "from pyspark.sql.functions import sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d45b2681-3b6c-4347-b0b2-205304c91387",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 13:>                                                         (0 + 2) / 2]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-------------------+\n",
      "|                NAME|TOTAL_CONTRIBUTIONS|\n",
      "+--------------------+-------------------+\n",
      "|     MELLON, TIMOTHY|           55003300|\n",
      "|          ONE NATION|           18400000|\n",
      "|FUTURE FORWARD US...|           15190058|\n",
      "|SECURING AMERICAN...|           15000000|\n",
      "|          MUSK, ELON|           14950000|\n",
      "|CLEMENT, CHRISTIN...|           12000564|\n",
      "|     SINGER, PAUL E.|           10150000|\n",
      "|BLOOMBERG, MICHAE...|           10014900|\n",
      "|SINGER, PAUL ELLIOTT|           10000000|\n",
      "|AMERICAN ACTION N...|            7500000|\n",
      "+--------------------+-------------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "dataframe_api.groupBy(\"NAME\") \\\n",
    "    .agg(sum(\"TRANSACTION_AMT\")) \\\n",
    "    .withColumnRenamed(\"sum(TRANSACTION_AMT)\", \"TOTAL_CONTRIBUTIONS\") \\\n",
    "    .orderBy(\"TOTAL_CONTRIBUTIONS\", ascending=False) \\\n",
    "    .show(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d86034ac-3ba3-4a49-83b0-aa319788960c",
   "metadata": {},
   "source": [
    "#### EXPLANATION OF THE ABOVE CODE:\n",
    "##### 1. dataframe_api.groupBy(\"Name\"):\n",
    "- Groups the DataFrame rows by the NAME column.\n",
    "- Each unique NAME (individual contributor) becomes a group.\n",
    "##### 2. agg(sum(\"TRANSACTION_AMT\")):\n",
    "- Performs an aggregation on each group using the sum function.\n",
    "- Calculates the total of TRANSACTION_AMT for each contributor.\n",
    "##### 3. withColumnRenamed(\"sum(TRANSACTION_AMT)\", \"TOTAL_CONTRIBUTIONS\")\n",
    "- Renames the column sum(TRANSACTION_AMT) to TOTAL_CONTRIBUTIONS for better readability.\n",
    "##### 4. orderBy(\"TOTAL_CONTRIBUTIONS\", ascending=False):\n",
    "- Sorts the DataFrame in descending order of TOTAL_CONTRIBUTIONS.\n",
    "- Ensures that contributors with the highest total contributions appear first.\n",
    "##### 4. show(10):\n",
    "- Displays the top 10 rows of the sorted DataFrame in the output."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "833504a4-b9a9-4180-91cc-8dd1e65bb1e3",
   "metadata": {},
   "source": [
    "## Summary and Insights: DATA FRAME API"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c02120f3-4b9d-46e7-8b71-2b036e073cfe",
   "metadata": {},
   "source": [
    "### Findings:\n",
    "1. Top Contributors by Individual Transactions:\n",
    "- Timothy Mellon emerges as the leading contributor, with a single donation of  $50,000,000.\n",
    "\n",
    "- One Nation follows with $18,400,000\n",
    "\n",
    "2. Top Contributors by Total Contributions:\n",
    "- Timothy Mellon tops again, with a staggering total contribution of over $55,003,300 indicating repeated and significant financial support to political committees.\n",
    "    \n",
    "### Patterns and Trends Observed:\n",
    "1. High Dependency on Wealthy Donors: \n",
    "- Contributions are heavily skewed toward a few high-profile individuals and organizations, indicating a concentrated donor base.\n",
    "2. Prominent Individuals and Entities: \n",
    "- Contributors like Elon Musk and Timothy Mellon highlight the growing involvement of wealthy individuals in political funding.\n",
    "\n",
    "### Reflection on Findings:\n",
    "- The dominance of wealthy individuals and prominent organizations in the dataset is expected given their historical involvement in campaign funding.\n",
    "- Large donations are consistent with the fundraising trends observed in high-stakes elections, where major donors play a critical role.\n",
    "- The presence of well-known figures like Elon Musk among the top contributors highlights the crossover between corporate influence and political campaigns.\n",
    "\n",
    "### Significance in Political Campaigns and Elections:\n",
    "1. Fundraising Strategies:\n",
    "- Understanding the contributions landscape allows campaigns to identify key donors and tailor their outreach efforts accordingly.\n",
    "- Committees relying on large-scale donors must also balance the optics of donor dependency with grassroots support.\n",
    "2. Electoral Influence:\n",
    "- The concentration of financial power among a few individuals and entities may shape campaign strategies, resource allocation, and electoral outcomes.\n",
    "- Transparency in political funding remains crucial for maintaining public trust and accountability.   \n",
    "3. Broader Implications:\n",
    "- These findings underscore the evolving role of high-profile donors and organizations in shaping the political agenda and influencing policy discussions.\n",
    "- The data highlights the need for continued monitoring and analysis of campaign contributions to ensure fair and transparent electoral processes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2aaa76d4-cffe-4b2b-8568-ea8349deb74d",
   "metadata": {},
   "source": [
    "### DATA ANALYSIS PART 3: SQL WITH DATA FRAME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "fa2e46c2-7c31-46f8-a799-14f841ebd982",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We create a temporary SQL view named \"dataframe_sql\" from the DataFrame dataframe_api\n",
    "# The allows to query the DataFrame using SQL syntax instead of PySpark DataFrame methods.\n",
    "dataframe_api.createOrReplaceTempView(\"dataframe_sql\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "6c6eda92-15c0-46ca-9efd-17617bba9d47",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 14:======================================>                   (4 + 2) / 6]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+\n",
      "|count(1)|\n",
      "+--------+\n",
      "| 3846794|\n",
      "+--------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# An SQL query to count the total number of rows in the dataframe_sql \n",
    "sqlc.sql(\"SELECT COUNT(*) FROM dataframe_sql\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6df64e6-4d2d-4c24-a4f7-30236cfb2a46",
   "metadata": {},
   "source": [
    "### 1. The top 10 individual contributor’s name, the contributor's occupation, and the transaction amount ordering them by the transaction amount in descending order."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "431a4b52-32a9-41c2-b31a-91077a4256a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 17:================================================>         (5 + 1) / 6]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-------------+---------------+\n",
      "|                NAME|   OCCUPATION|TRANSACTION_AMT|\n",
      "+--------------------+-------------+---------------+\n",
      "|     MELLON, TIMOTHY|  INVESTMENTS|       50000000|\n",
      "|          ONE NATION|         NULL|       18400000|\n",
      "|SECURING AMERICAN...|         NULL|       15000000|\n",
      "|FUTURE FORWARD US...|         NULL|       15000000|\n",
      "|CLEMENT, CHRISTIN...|SELF EMPLOYED|       12000000|\n",
      "|BLOOMBERG, MICHAE...|      FOUNDER|       10000000|\n",
      "|     SINGER, PAUL E.|    PRESIDENT|       10000000|\n",
      "|SINGER, PAUL ELLIOTT|    PRESIDENT|       10000000|\n",
      "|BRICK BY BRICK FO...|         NULL|        5000000|\n",
      "|AMERICAN ACTION N...|         NULL|        5000000|\n",
      "+--------------------+-------------+---------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "sqlc.sql(\"\"\"\n",
    "     SELECT \n",
    "         NAME, \n",
    "         OCCUPATION, \n",
    "         TRANSACTION_AMT \n",
    "     FROM\n",
    "         dataframe_sql \n",
    "     ORDER BY\n",
    "         TRANSACTION_AMT DESC\n",
    "    \"\"\").show(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62cfabb6-4089-454a-b6f3-1cf12bd12fe8",
   "metadata": {},
   "source": [
    "#### EXPLANATION OF THE ABOVE CODE:\n",
    "##### 1. SELECT NAME, OCCUPATION, TRANSACTION_AMT:\n",
    "- Filters rows in the DataFrame dataframe_api where the TRANSACTION_AMT column is greater than 5000.\n",
    "##### 2. SELECT(\"NAME\", \"CMTE_ID\", \"TRANSACTION_AMT\"):\n",
    "- Specifies the columns to be retrieved.\n",
    "##### 3. FROM dataframe_sql:\n",
    "- Specifies the temporary SQL view (dataframe_sql) as the data source for the query.\n",
    "##### 4. ORDER BY TRANSACTION_AMT DESC:\n",
    "- Sorts the results by the TRANSACTION_AMT column in descending order.\n",
    "##### 5. show(10):\n",
    "- Displays the top 10 rows of the sorted DataFrame in the output.\n",
    "##### 6. sqlc.sql(\"\"\"...\"\"\"):\n",
    "- Executes the SQL query written within the triple quotes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1f84a29-8f51-46a3-a522-2e4b5da16125",
   "metadata": {},
   "source": [
    "### 2. The top 10 committees based on their total individual contributions on a given date. Providing the committee ID, the transaction date and the transaction amount ordered by the total transaction amount in descending order."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "711de0da-1fbd-48dc-9d3a-882f7efa20c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 18:================================================>         (5 + 1) / 6]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+--------------+------------------------+\n",
      "|  CMTE_ID|TRANSACTION_DT|TOTAL_TRANSACTION_AMOUNT|\n",
      "+---------+--------------+------------------------+\n",
      "|C00401224|       7232024|                16219539|\n",
      "|C00744946|       7232024|                 8930581|\n",
      "|C00703975|       7232024|                 6353147|\n",
      "|C00504530|       7232024|                 5025208|\n",
      "|C00867937|       7232024|                 3665789|\n",
      "|C00694323|       7232024|                 2657790|\n",
      "|C00873893|       7232024|                 1208679|\n",
      "|C00418897|       7232024|                 1000000|\n",
      "|C00000935|       7232024|                  941803|\n",
      "|C00010603|       7232024|                  765994|\n",
      "+---------+--------------+------------------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "sqlc.sql(\"\"\"\n",
    "     SELECT \n",
    "         CMTE_ID, \n",
    "         TRANSACTION_DT, \n",
    "         SUM(TRANSACTION_AMT) AS TOTAL_TRANSACTION_AMOUNT \n",
    "     FROM\n",
    "         dataframe_sql \n",
    "     WHERE\n",
    "         TRANSACTION_DT = 07232024\n",
    "     GROUP BY\n",
    "         CMTE_ID, TRANSACTION_DT\n",
    "     ORDER BY\n",
    "         TOTAL_TRANSACTION_AMOUNT DESC\n",
    "    \"\"\").show(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "869f4d61-d226-480c-8e4e-522f91ee18f6",
   "metadata": {},
   "source": [
    "#### EXPLANATION OF THE ABOVE CODE:\n",
    "##### 1. SELECT NAME, OCCUPATION, TRANSACTION_AMT:\n",
    "- Filters rows in the DataFrame dataframe_api where the TRANSACTION_AMT column is greater than 5000.\n",
    "##### 2. SELECT CMTE_ID, TRANSACTION_DT, SUM(TRANSACTION_AMT) AS TOTAL_TRANSACTION_AMOUNT:\n",
    "- Specifies the columns to be retrieved.\n",
    "##### 3. FROM dataframe_sql:\n",
    "- Specifies the temporary SQL view (dataframe_sql) as the data source for the query.\n",
    "##### 4. WHERE TRANSACTION_DT = 07232024:\n",
    "- Filters the data to include only rows where the TRANSACTION_DT (transaction date) equals July 23, 2024.\n",
    "##### 5. GROUP BY CMTE_ID, TRANSACTION_DT:\n",
    "- Groups the data by the CMTE_ID (committee ID) and TRANSACTION_DT (transaction date).\n",
    "- Within each group, the SUM(TRANSACTION_AMT) computes the total contribution amount\n",
    "##### 6. ORDER BY TRANSACTION_AMT DESC:\n",
    "- Sorts the results by the TRANSACTION_AMT column in descending order.\n",
    "##### 7. show(10):\n",
    "- Displays the top 10 rows of the sorted DataFrame in the output.\n",
    "##### 8. sqlc.sql(\"\"\"...\"\"\"):\n",
    "- Executes the SQL query written within the triple quotes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f43d51cc-e6db-4e54-a3a9-b9e442d42a47",
   "metadata": {},
   "source": [
    "## Summary and Insights: SQL WITH DATA FRAME"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "875cecc4-e872-42f3-b650-ea06cdc3256a",
   "metadata": {},
   "source": [
    "### Findings:\n",
    "- The data analysis revealed that Timothy Mellon is a significant contributor, with a transaction amount of $50,000,000. \n",
    "\n",
    "- Followed by contributions from committees such as One Nation with $18,400,000.\n",
    "- These substantial contributions highlight the role of high-net-worth individuals and organizations in political funding.\n",
    "- The SQL queries also identified committees receiving the highest contributions on specific dates, such as July 23, 2024, showing peaks in fundraising activities around critical campaign timelines.\n",
    "    \n",
    "### Patterns and Trends Observed:\n",
    "- Contributions are highly skewed, with a small number of individuals and committees making exceptionally large contributions. This trend reflects the unequal distribution of financial influence in political campaigns.\n",
    "- Certain committees and contributors consistently appear at the top, indicating their significant and recurring role in funding.\n",
    "\n",
    "### Significance in Political Campaigns and Elections:\n",
    "- These findings emphasize the pivotal role of financial contributions in shaping election campaigns. Large donors and committees with substantial funds can significantly influence political narratives and outcomes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cee9d58-f6f1-4643-a996-59bf16a3ecb6",
   "metadata": {},
   "source": [
    "# FINAL CONCLUSION"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c3e4808-3d2d-4d63-bfd5-d09611209687",
   "metadata": {},
   "source": [
    "This data analysis project on individual contributions to Federal Committees covering presidential, senate and house committees has provided significant insights into the dynamics of political campaign funding during the period from June 20, 2024 to July 23, 2024. Through systematic data collection, processing and analysis using Apache Spark, we effectively uncovered key patterns and trends in contributions showcasing the power and efficiency of big data tools in handling large datasets.\n",
    "\n",
    "The data processing phase demonstrated the utility of tools like Spark for efficient handling of large, complex datasets through RDDs, DataFrame APIs and SQL queries. The data analysis revealed key contributors and patterns highlighting the role of a few high net-worth individuals and influential committees in shaping the political funding landscape. \n",
    "\n",
    "This analysis underscores the critical importance of transparency and data-driven decision-making in understanding political financing. By leveraging modern tools like Spark, we demonstrated the potential for analyzing large-scale datasets to derive actionable insights, which can be used to inform policy discussions and improve the integrity of political processes. Overall, this project showcases how big data and analytics can transform our understanding of complex domains such as campaign financing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "302abf83-90c5-430e-be99-617bb4ed6532",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
